{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24917570-492f-4cda-bd65-54a9a4d70974",
   "metadata": {},
   "source": [
    "### Labor force participation in times of COVID-19 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3e8b8-cdbb-4889-a4ff-5f68ac544a30",
   "metadata": {},
   "source": [
    "First, let's import our packages necessary to download the data, work with it, create plots and run our exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR IMPORTING DATA\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# FOR API\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Union, Optional\n",
    "\n",
    "# FOR CHARTS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81275b26-cca3-4df5-a925-e1041e802eac",
   "metadata": {},
   "source": [
    "First, let's set our API Key to be used for BLS, which is saved on a separate .txt file for security purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = open(\"BLS_API_KEY.txt\")\n",
    "apikey = txt_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the knowledge learned in class, we copy and adapt a function to download data from the BLS API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_for_series(\n",
    "        series_ids: List[str], \n",
    "        startyear: Union[int,str], \n",
    "        endyear: Union[int,str],\n",
    "        apikey:Optional[str]=None,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Request data for all ``series_ids`` between ``startyear`` and ``endyear``\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series_ids: List[str]\n",
    "        A list of all BLS series IDs for which to request data\n",
    "    \n",
    "    startyear, endyear: Union[int,str]\n",
    "        Starting and ending years for period of data. All intervals between\n",
    "        these two years (inclusive) will be reported\n",
    "    \n",
    "    apikey: Optional[str]\n",
    "        A registration or API key to enable more extensive use of the\n",
    "        api and more detailed results\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    responses: List[requests.Response]\n",
    "        A list of `Response` objects from the requests library\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The BLS API only allows 25 series to be requested in a single call to the API\n",
    "    This function allows an arbitrary number of series. The function first checks how \n",
    "    many series_ids are requested, and then makes two recursive calls to this function:\n",
    "    \n",
    "    (1) the first 25 series IDs are fetched and \n",
    "    (2) the rest of the series ids. \n",
    "    \n",
    "    If the second request contains more than 25 series, another split is made and a pair of \n",
    "    recursive function calls are issued.\n",
    "    \n",
    "    Also note that the response objects from ``requests`` are not processed or validated\n",
    "    in any way -- this is up to the caller of this routine.\n",
    "    \n",
    "    Finally, if an apikey is given, then a catalog of series metadata will be requested\n",
    "    and returned from this function. This is necessary for getting the metadata DataFrame\n",
    "    from the functions ``make_dfs_from_series``, ``unpack_response``, and \n",
    "    ``unpack_all_responses`` functions below.\n",
    "    \"\"\"\n",
    "    n_series = len(series_ids)\n",
    "    if n_series > 25:  #for more than 25, you work on this\n",
    "        parts = []\n",
    "        # make common keyword arguments so we don't have to type twice below\n",
    "        kw = dict(endyear=endyear, startyear=startyear, apikey=apikey)\n",
    "        parts.extend(request_for_series(series_ids[:25], **kw))\n",
    "        parts.extend(request_for_series(series_ids[25:], **kw))\n",
    "        return parts\n",
    "    else:\n",
    "        headers = {'Content-type': 'application/json'}\n",
    "        params = {\n",
    "            \"seriesid\": series_ids, \n",
    "            \"startyear\":startyear, \n",
    "            \"endyear\": endyear,\n",
    "        }\n",
    "        if apikey is not None:\n",
    "            params[\"catalog\"] = True\n",
    "            params[\"registrationkey\"] = apikey\n",
    "        \n",
    "        # convert params dictionary to json string\n",
    "        data = json.dumps(params)\n",
    "        p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "        return [p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to validate the search through the website (i.e. to see if it works):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_response(res: requests.Response):\n",
    "    \"\"\"\n",
    "    Check a response from the BLS API for success\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res: requests.Response\n",
    "        The requests object returned from iteracting with BLS API\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Right now we just check for success at the http protocol level\n",
    "    and don't do any checking specific to the BLS api\n",
    "    \"\"\"\n",
    "    code = res.status_code\n",
    "    if code > 299:\n",
    "        raise ValueError(f\"Response error with code {code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is to transfer the data into dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dfs_from_series(series_results):\n",
    "    \"\"\"\n",
    "    Unpack a series response object into data and metadata pandas objects\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series_results: dict\n",
    "        A dictionary returned from the `timeseries/data` endpoint of the\n",
    "        BLS api. An example object for this parameter would be found at\n",
    "        ``res.json()[\"Results\"][\"series\"][0]`` where ``res`` is the \n",
    "        ``requests.Response`` obtained from interacting with the API endpoint.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data: pd.DataFrame\n",
    "        A pandas DataFrame containing the actual observations of the data series\n",
    "    \n",
    "    metadata: Optional[pd.Series]\n",
    "        If the ``\"catgalog\"`` key exists in ``series_results``, then ``metadata``\n",
    "        is a pandas Series containing the catalog information. If ``\"catalog\"``\n",
    "        is found, then this is None    \n",
    "    \"\"\"\n",
    "    #extract series ID and store as a variable\n",
    "    series_id = series_results[\"seriesID\"]\n",
    "    \n",
    "    #next, we create a panda dataframe, reading a list of dict\n",
    "    #we attach ID as an additional column\n",
    "    data = pd.DataFrame(series_results[\"data\"]).assign(series_id=series_id)\n",
    "    \n",
    "    #if catalog was attached, we create a series\n",
    "    #if not, we don't\n",
    "    if \"catalog\" in series_results:\n",
    "        metadata = pd.Series(series_results[\"catalog\"])\n",
    "    else:\n",
    "        metadata = None\n",
    "    \n",
    "    return data, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two functions will unpack the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_response(res: requests.Response):\n",
    "    \"\"\"\n",
    "    Unpack the response for requesting one or more timeseries \n",
    "    from the BLS api\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res: requests.Response\n",
    "        The object returned from interacting with the ``timeseries/data``\n",
    "        BLS API endpoint via the reuqests library\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    datasets: List[Tuple[pd.DataFrame, pd.Series]]\n",
    "        For each BLS series contained in ``res``, a tuple with the \n",
    "        timeseries observations and series metadata will be returned.\n",
    "        The observations are a pandas DataFrame and the metadata is a\n",
    "        pandas Series. These pairs of (data, metadata) are returned\n",
    "        in a list\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "    See ``make_dfs_from_series`` for more information on content\n",
    "    of output.\n",
    "    \"\"\"\n",
    "    #compute the json form of our response\n",
    "    js = res.json()\n",
    "    #now we map the results and series as above when we created data and meta\n",
    "    \n",
    "    return list(map(make_dfs_from_series, js[\"Results\"][\"series\"]))\n",
    "\n",
    "\n",
    "def unpack_all_responses(all_res: List[requests.Response]):\n",
    "    \"\"\"\n",
    "    Given a list of responses from the BLS API, extract and \n",
    "    return all data and metadata\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    all_res: List[requests.Response])\n",
    "        Each item in this list is the result of using ``requests`` to \n",
    "        fetch data from ``timeseries/data`` endpoint of the BLS API.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    data: pd.DataFrame\n",
    "        A pandas DataFrame containing all timeseries observations included\n",
    "        in any of the responses in ``all_res``\n",
    "    \n",
    "    metadata: pd.DataFrame\n",
    "        Detailed metadata about each series, if such metadata exists in the\n",
    "        response objects\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "    See ``unpack_response`` and ``make_dfs_from_series`` functions\n",
    "        \n",
    "    \"\"\"\n",
    "    #make unpacked an empty list\n",
    "    unpacked = []\n",
    "    \n",
    "    #then use a for function to unpack all of them (list)\n",
    "    for res in all_res:\n",
    "        unpacked.extend(unpack_response(res))\n",
    "    \n",
    "    data_dfs, metadata_series = list(zip(*unpacked))\n",
    "    \n",
    "    #stack all data one on the top of the other\n",
    "    data = pd.concat(data_dfs, ignore_index=True)\n",
    "    \n",
    "    #add the metadata and stack them as columns\n",
    "    metadata = pd.concat([x for x in metadata_series if x is not None], axis=1).T\n",
    "    \n",
    "    return data, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's find all the series of interest.\n",
    "\n",
    "If it ends with:\n",
    "\n",
    "3. Seasonally adjustment unemployment rate. \n",
    "4. Seasonally adjusted unemployment level\n",
    "5. Seasonally adjusted employment level\n",
    "6. Seasonally adjusted labor force level\n",
    "7. Seasonally adjusted employment-population ratio\n",
    "8. Seasonally adjusted labor force participation ratio\n",
    "\n",
    "We will use only 3 and 8 in our analysis. The first two numbers refer to the state from which the data is extracted.\n",
    "\n",
    "Source: https://www.bls.gov/lau/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_ids = [\n",
    "    \"LASST010000000000003\", \n",
    "    \"LASST010000000000008\", \n",
    "    \"LASST020000000000003\", \n",
    "    \"LASST020000000000008\", \n",
    "    \"LASST030000000000003\",\n",
    "    \"LASST030000000000008\", \n",
    "    \"LASST040000000000003\",\n",
    "    \"LASST040000000000008\", \n",
    "    \"LASST050000000000003\", \n",
    "    \"LASST050000000000008\", \n",
    "    \"LASST060000000000003\", \n",
    "    \"LASST060000000000008\", \n",
    "    \"LASST070000000000003\", \n",
    "    \"LASST070000000000008\", \n",
    "    \"LASST080000000000003\", \n",
    "    \"LASST080000000000008\", \n",
    "    \"LASST090000000000003\",\n",
    "    \"LASST090000000000008\", \n",
    "    \"LASST100000000000003\",\n",
    "    \"LASST100000000000008\", \n",
    "    \"LASST110000000000003\", \n",
    "    \"LASST110000000000008\", \n",
    "    \"LASST120000000000003\", \n",
    "    \"LASST120000000000008\", \n",
    "    \"LASST130000000000003\", \n",
    "    \"LASST130000000000008\", \n",
    "    \"LASST140000000000003\", \n",
    "    \"LASST140000000000008\", \n",
    "    \"LASST150000000000003\", \n",
    "    \"LASST150000000000008\", \n",
    "    \"LASST160000000000003\", \n",
    "    \"LASST160000000000008\", \n",
    "    \"LASST170000000000003\", \n",
    "    \"LASST170000000000008\", \n",
    "    \"LASST180000000000003\", \n",
    "    \"LASST180000000000008\", \n",
    "    \"LASST190000000000003\", \n",
    "    \"LASST190000000000008\",\n",
    "    \"LASST200000000000003\", \n",
    "    \"LASST200000000000008\", \n",
    "    \"LASST210000000000003\", \n",
    "    \"LASST210000000000008\", \n",
    "    \"LASST220000000000003\", \n",
    "    \"LASST220000000000008\", \n",
    "    \"LASST230000000000003\", \n",
    "    \"LASST230000000000008\", \n",
    "    \"LASST240000000000003\", \n",
    "    \"LASST240000000000008\", \n",
    "    \"LASST250000000000003\", \n",
    "    \"LASST250000000000008\", \n",
    "    \"LASST260000000000003\", \n",
    "    \"LASST260000000000008\", \n",
    "    \"LASST270000000000003\", \n",
    "    \"LASST270000000000008\", \n",
    "    \"LASST280000000000003\", \n",
    "    \"LASST280000000000008\", \n",
    "    \"LASST290000000000003\", \n",
    "    \"LASST290000000000008\", \n",
    "    \"LASST300000000000003\", \n",
    "    \"LASST300000000000008\", \n",
    "    \"LASST310000000000003\",\n",
    "    \"LASST310000000000008\", \n",
    "    \"LASST320000000000003\", \n",
    "    \"LASST320000000000008\", \n",
    "    \"LASST330000000000003\", \n",
    "    \"LASST330000000000008\",\n",
    "    \"LASST340000000000003\", \n",
    "    \"LASST340000000000008\", \n",
    "    \"LASST350000000000003\",\n",
    "    \"LASST350000000000008\",  \n",
    "    \"LASST360000000000003\", \n",
    "    \"LASST360000000000008\", \n",
    "    \"LASST370000000000003\", \n",
    "    \"LASST380000000000008\", \n",
    "    \"LASST370000000000003\", \n",
    "    \"LASST380000000000008\", \n",
    "    \"LASST370000000000003\", \n",
    "    \"LASST380000000000008\", \n",
    "    \"LASST390000000000003\", \n",
    "    \"LASST390000000000008\",    \n",
    "    \"LASST400000000000003\", \n",
    "    \"LASST400000000000008\", \n",
    "    \"LASST410000000000003\", \n",
    "    \"LASST410000000000008\", \n",
    "    \"LASST420000000000003\", \n",
    "    \"LASST420000000000008\", \n",
    "    \"LASST430000000000003\", \n",
    "    \"LASST430000000000008\", \n",
    "    \"LASST440000000000003\", \n",
    "    \"LASST440000000000008\", \n",
    "    \"LASST450000000000003\", \n",
    "    \"LASST450000000000008\", \n",
    "    \"LASST460000000000003\", \n",
    "    \"LASST460000000000008\", \n",
    "    \"LASST470000000000003\", \n",
    "    \"LASST470000000000008\", \n",
    "    \"LASST480000000000003\", \n",
    "    \"LASST480000000000008\", \n",
    "    \"LASST490000000000003\", \n",
    "    \"LASST490000000000008\", \n",
    "    \"LASST500000000000003\", \n",
    "    \"LASST500000000000008\",\n",
    "    \"LASST510000000000003\", \n",
    "    \"LASST510000000000008\",\n",
    "    \"LASST520000000000003\",\n",
    "    \"LASST520000000000008\",\n",
    "    \"LASST530000000000003\", \n",
    "    \"LASST530000000000008\", \n",
    "    \"LASST540000000000003\", \n",
    "    \"LASST540000000000008\",     \n",
    "    \"LASST550000000000003\", \n",
    "    \"LASST550000000000008\", \n",
    "    \"LASST560000000000003\", \n",
    "    \"LASST560000000000008\",\n",
    "]\n",
    "\n",
    "# make requests, get responses\n",
    "responses1 = request_for_series(series_ids, \"1976\", \"1995\", apikey=apikey)\n",
    "\n",
    "# validate the responses\n",
    "[check_response(r) for r in responses1]\n",
    "\n",
    "# extract data and metadata from responses\n",
    "df1, metadata1 = unpack_all_responses(responses1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data for date range: 1996 - 2015\n",
    "responses2 = request_for_series(series_ids, \"1996\", \"2015\", apikey=apikey)\n",
    "df2, metadata2 = unpack_all_responses(responses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data for date range: 2016 - 2021\n",
    "responses3 = request_for_series(series_ids, \"2016\", \"2021\", apikey=apikey)\n",
    "df3, metadata3 = unpack_all_responses(responses3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will also incorporate data related to the dates when states announced that Pandemic Unemployment Assistance benefits (PUA)\n",
    "\n",
    "will expire (announce_ui) in additon to the actual date when PUA ended (expired_ui). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "announce_url = \"https://raw.githubusercontent.com/vgm236/ferrante_moreira_data_project/main/Data/announced_dates_ui_expiration.csv\"\n",
    "announce_ui = pd.read_csv(announce_url)\n",
    "\n",
    "expired_url = \"https://raw.githubusercontent.com/vgm236/ferrante_moreira_data_project/main/Data/effective_dates_ui_expiration.csv\"\n",
    "expired_ui = pd.read_csv(expired_url)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "167380c844cb8dab65f7a2242fcdd292fd16a45a4bab8a9de8ac74aeee39fadd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
