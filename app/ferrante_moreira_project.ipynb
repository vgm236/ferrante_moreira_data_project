{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24917570-492f-4cda-bd65-54a9a4d70974",
   "metadata": {},
   "source": [
    "### Labor force participation in times of COVID-19 ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac3e8b8-cdbb-4889-a4ff-5f68ac544a30",
   "metadata": {},
   "source": [
    "First, let's import our packages necessary to download the data, work with it, create plots and run our exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91819d2f-8920-4a2d-a880-0e0fc3158a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR IMPORTING DATA\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# FOR API\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Union, Optional\n",
    "\n",
    "# FOR CHARTS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81275b26-cca3-4df5-a925-e1041e802eac",
   "metadata": {},
   "source": [
    "First, let's set our API Key to be used for BLS, which is saved on a separate .txt file for security purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e920288-7fa6-4ff8-9620-e8d73441bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = open(\"BLS_API_KEY.txt\")\n",
    "apikey = txt_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00f816-67e9-4a81-94eb-173119d21ac9",
   "metadata": {},
   "source": [
    "Using the knowledge learned in class, we copy and adapt a function to download data from the BLS API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ca0a3c-92cd-4358-b7e8-1e3fb1afd827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_for_series(\n",
    "        series_ids: List[str], \n",
    "        startyear: Union[int,str], \n",
    "        endyear: Union[int,str],\n",
    "        apikey:Optional[str]=None,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Request data for all ``series_ids`` between ``startyear`` and ``endyear``\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series_ids: List[str]\n",
    "        A list of all BLS series IDs for which to request data\n",
    "    \n",
    "    startyear, endyear: Union[int,str]\n",
    "        Starting and ending years for period of data. All intervals between\n",
    "        these two years (inclusive) will be reported\n",
    "    \n",
    "    apikey: Optional[str]\n",
    "        A registration or API key to enable more extensive use of the\n",
    "        api and more detailed results\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    responses: List[requests.Response]\n",
    "        A list of `Response` objects from the requests library\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    The BLS API only allows 25 series to be requested in a single call to the API\n",
    "    This function allows an arbitrary number of series. The function first checks how \n",
    "    many series_ids are requested, and then makes two recursive calls to this function:\n",
    "    \n",
    "    (1) the first 25 series IDs are fetched and \n",
    "    (2) the rest of the series ids. \n",
    "    \n",
    "    If the second request contains more than 25 series, another split is made and a pair of \n",
    "    recursive function calls are issued.\n",
    "    \n",
    "    Also note that the response objects from ``requests`` are not processed or validated\n",
    "    in any way -- this is up to the caller of this routine.\n",
    "    \n",
    "    Finally, if an apikey is given, then a catalog of series metadata will be requested\n",
    "    and returned from this function. This is necessary for getting the metadata DataFrame\n",
    "    from the functions ``make_dfs_from_series``, ``unpack_response``, and \n",
    "    ``unpack_all_responses`` functions below.\n",
    "    \"\"\"\n",
    "    n_series = len(series_ids)\n",
    "    if n_series > 25:  #for more than 25, you work on this\n",
    "        parts = []\n",
    "        # make common keyword arguments so we don't have to type twice below\n",
    "        kw = dict(endyear=endyear, startyear=startyear, apikey=apikey)\n",
    "        parts.extend(request_for_series(series_ids[:25], **kw))\n",
    "        parts.extend(request_for_series(series_ids[25:], **kw))\n",
    "        return parts\n",
    "    else:\n",
    "        headers = {'Content-type': 'application/json'}\n",
    "        params = {\n",
    "            \"seriesid\": series_ids, \n",
    "            \"startyear\":startyear, \n",
    "            \"endyear\": endyear,\n",
    "        }\n",
    "        if apikey is not None:\n",
    "            params[\"catalog\"] = True\n",
    "            params[\"registrationkey\"] = apikey\n",
    "        \n",
    "        # convert params dictionary to json string\n",
    "        data = json.dumps(params)\n",
    "        p = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/', data=data, headers=headers)\n",
    "        return [p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c11983b-77e6-4c79-88a3-9bb56ce370a7",
   "metadata": {},
   "source": [
    "This function is used to validate the search through the website (i.e. to see if it works):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f387d6-0412-48c9-8fcd-f6c39eed191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_response(res: requests.Response):\n",
    "    \"\"\"\n",
    "    Check a response from the BLS API for success\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res: requests.Response\n",
    "        The requests object returned from iteracting with BLS API\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Right now we just check for success at the http protocol level\n",
    "    and don't do any checking specific to the BLS api\n",
    "    \"\"\"\n",
    "    code = res.status_code\n",
    "    if code > 299:\n",
    "        raise ValueError(f\"Response error with code {code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8ffdc4-1c27-48b9-8827-9aa4716973a6",
   "metadata": {},
   "source": [
    "This function is to transfer the data into dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65bee868-cb22-4836-8ea2-c16f2593f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dfs_from_series(series_results):\n",
    "    \"\"\"\n",
    "    Unpack a series response object into data and metadata pandas objects\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    series_results: dict\n",
    "        A dictionary returned from the `timeseries/data` endpoint of the\n",
    "        BLS api. An example object for this parameter would be found at\n",
    "        ``res.json()[\"Results\"][\"series\"][0]`` where ``res`` is the \n",
    "        ``requests.Response`` obtained from interacting with the API endpoint.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data: pd.DataFrame\n",
    "        A pandas DataFrame containing the actual observations of the data series\n",
    "    \n",
    "    metadata: Optional[pd.Series]\n",
    "        If the ``\"catgalog\"`` key exists in ``series_results``, then ``metadata``\n",
    "        is a pandas Series containing the catalog information. If ``\"catalog\"``\n",
    "        is found, then this is None    \n",
    "    \"\"\"\n",
    "    #extract series ID and store as a variable\n",
    "    series_id = series_results[\"seriesID\"]\n",
    "    \n",
    "    #next, we create a panda dataframe, reading a list of dict\n",
    "    #we attach ID as an additional column\n",
    "    data = pd.DataFrame(series_results[\"data\"]).assign(series_id=series_id)\n",
    "    \n",
    "    #if catalog was attached, we create a series\n",
    "    #if not, we don't\n",
    "    if \"catalog\" in series_results:\n",
    "        metadata = pd.Series(series_results[\"catalog\"])\n",
    "    else:\n",
    "        metadata = None\n",
    "    \n",
    "    return data, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83629ba5-d955-4872-8098-18c459fed65c",
   "metadata": {},
   "source": [
    "These two functions will unpack the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "412933ab-aee2-4791-a993-6582f1ce6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_response(res: requests.Response):\n",
    "    \"\"\"\n",
    "    Unpack the response for requesting one or more timeseries \n",
    "    from the BLS api\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res: requests.Response\n",
    "        The object returned from interacting with the ``timeseries/data``\n",
    "        BLS API endpoint via the reuqests library\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    datasets: List[Tuple[pd.DataFrame, pd.Series]]\n",
    "        For each BLS series contained in ``res``, a tuple with the \n",
    "        timeseries observations and series metadata will be returned.\n",
    "        The observations are a pandas DataFrame and the metadata is a\n",
    "        pandas Series. These pairs of (data, metadata) are returned\n",
    "        in a list\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "    See ``make_dfs_from_series`` for more information on content\n",
    "    of output.\n",
    "    \"\"\"\n",
    "    #compute the json form of our response\n",
    "    js = res.json()\n",
    "    #now we map the results and series as above when we created data and meta\n",
    "    \n",
    "    return list(map(make_dfs_from_series, js[\"Results\"][\"series\"]))\n",
    "\n",
    "\n",
    "def unpack_all_responses(all_res: List[requests.Response]):\n",
    "    \"\"\"\n",
    "    Given a list of responses from the BLS API, extract and \n",
    "    return all data and metadata\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    all_res: List[requests.Response])\n",
    "        Each item in this list is the result of using ``requests`` to \n",
    "        fetch data from ``timeseries/data`` endpoint of the BLS API.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    data: pd.DataFrame\n",
    "        A pandas DataFrame containing all timeseries observations included\n",
    "        in any of the responses in ``all_res``\n",
    "    \n",
    "    metadata: pd.DataFrame\n",
    "        Detailed metadata about each series, if such metadata exists in the\n",
    "        response objects\n",
    "    \n",
    "    See Also\n",
    "    --------\n",
    "    See ``unpack_response`` and ``make_dfs_from_series`` functions\n",
    "        \n",
    "    \"\"\"\n",
    "    #make unpacked an empty list\n",
    "    unpacked = []\n",
    "    \n",
    "    #then use a for function to unpack all of them (list)\n",
    "    for res in all_res:\n",
    "        unpacked.extend(unpack_response(res))\n",
    "    \n",
    "    data_dfs, metadata_series = list(zip(*unpacked))\n",
    "    \n",
    "    #stack all data one on the top of the other\n",
    "    data = pd.concat(data_dfs, ignore_index=True)\n",
    "    \n",
    "    #add the metadata and stack them as columns\n",
    "    metadata = pd.concat([x for x in metadata_series if x is not None], axis=1).T\n",
    "    \n",
    "    return data, metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb995861-0c7b-4b92-a0f4-f9a3d3fb6bd7",
   "metadata": {},
   "source": [
    "Now, let's find all the series of interest.\n",
    "\n",
    "If it ends with:\n",
    "\n",
    "3. Seasonally adjustment unemployment rate. \n",
    "4. Seasonally adjusted unemployment level\n",
    "5. Seasonally adjusted employment level\n",
    "6. Seasonally adjusted labor force level\n",
    "7. Seasonally adjusted employment-population ratio\n",
    "8. Seasonally adjusted labor force participation ratio\n",
    "\n",
    "We will use only 3 and 8 in our analysis. The first two numbers refer to the state from which the data is extracted.\n",
    "\n",
    "Source: https://www.bls.gov/lau/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d9fb72-0ad8-4ca3-9a7c-b2d3d133fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_ids = [\n",
    "    \"LASST010000000000003\", \n",
    "    \"LASST010000000000008\", \n",
    "    \"LASST020000000000003\", \n",
    "    \"LASST020000000000008\", \n",
    "    \"LASST030000000000003\",\n",
    "    \"LASST030000000000008\", \n",
    "    \"LASST040000000000003\",\n",
    "    \"LASST040000000000008\", \n",
    "    \"LASST050000000000003\", \n",
    "    \"LASST050000000000008\", \n",
    "    \"LASST060000000000003\", \n",
    "    \"LASST060000000000008\", \n",
    "    \"LASST070000000000003\", \n",
    "    \"LASST070000000000008\", \n",
    "    \"LASST080000000000003\", \n",
    "    \"LASST080000000000008\", \n",
    "    \"LASST090000000000003\",\n",
    "    \"LASST090000000000008\", \n",
    "    \"LASST100000000000003\",\n",
    "    \"LASST100000000000008\", \n",
    "    \"LASST110000000000003\", \n",
    "    \"LASST110000000000008\", \n",
    "    \"LASST120000000000003\", \n",
    "    \"LASST120000000000008\", \n",
    "    \"LASST130000000000003\", \n",
    "    \"LASST130000000000008\", \n",
    "    \"LASST140000000000003\", \n",
    "    \"LASST140000000000008\", \n",
    "    \"LASST150000000000003\", \n",
    "    \"LASST150000000000008\", \n",
    "    \"LASST160000000000003\", \n",
    "    \"LASST160000000000008\", \n",
    "    \"LASST170000000000003\", \n",
    "    \"LASST170000000000008\", \n",
    "    \"LASST180000000000003\", \n",
    "    \"LASST180000000000008\", \n",
    "    \"LASST190000000000003\", \n",
    "    \"LASST190000000000008\",\n",
    "    \"LASST200000000000003\", \n",
    "    \"LASST200000000000008\", \n",
    "    \"LASST210000000000003\", \n",
    "    \"LASST210000000000008\", \n",
    "    \"LASST220000000000003\", \n",
    "    \"LASST220000000000008\", \n",
    "    \"LASST230000000000003\", \n",
    "    \"LASST230000000000008\", \n",
    "    \"LASST240000000000003\", \n",
    "    \"LASST240000000000008\", \n",
    "    \"LASST250000000000003\", \n",
    "    \"LASST250000000000008\", \n",
    "    \"LASST260000000000003\", \n",
    "    \"LASST260000000000008\", \n",
    "    \"LASST270000000000003\", \n",
    "    \"LASST270000000000008\", \n",
    "    \"LASST280000000000003\", \n",
    "    \"LASST280000000000008\", \n",
    "    \"LASST290000000000003\", \n",
    "    \"LASST290000000000008\", \n",
    "    \"LASST300000000000003\", \n",
    "    \"LASST300000000000008\", \n",
    "    \"LASST310000000000003\",\n",
    "    \"LASST310000000000008\", \n",
    "    \"LASST320000000000003\", \n",
    "    \"LASST320000000000008\", \n",
    "    \"LASST330000000000003\", \n",
    "    \"LASST330000000000008\",\n",
    "    \"LASST340000000000003\", \n",
    "    \"LASST340000000000008\", \n",
    "    \"LASST350000000000003\",\n",
    "    \"LASST350000000000008\",  \n",
    "    \"LASST360000000000003\", \n",
    "    \"LASST360000000000008\", \n",
    "    \"LASST370000000000003\", \n",
    "    \"LASST380000000000008\", \n",
    "    \"LASST370000000000003\", \n",
    "    \"LASST380000000000008\", \n",
    "    \"LASST370000000000003\", \n",
    "    \"LASST380000000000008\", \n",
    "    \"LASST390000000000003\", \n",
    "    \"LASST390000000000008\",    \n",
    "    \"LASST400000000000003\", \n",
    "    \"LASST400000000000008\", \n",
    "    \"LASST410000000000003\", \n",
    "    \"LASST410000000000008\", \n",
    "    \"LASST420000000000003\", \n",
    "    \"LASST420000000000008\", \n",
    "    \"LASST430000000000003\", \n",
    "    \"LASST430000000000008\", \n",
    "    \"LASST440000000000003\", \n",
    "    \"LASST440000000000008\", \n",
    "    \"LASST450000000000003\", \n",
    "    \"LASST450000000000008\", \n",
    "    \"LASST460000000000003\", \n",
    "    \"LASST460000000000008\", \n",
    "    \"LASST470000000000003\", \n",
    "    \"LASST470000000000008\", \n",
    "    \"LASST480000000000003\", \n",
    "    \"LASST480000000000008\", \n",
    "    \"LASST490000000000003\", \n",
    "    \"LASST490000000000008\", \n",
    "    \"LASST500000000000003\", \n",
    "    \"LASST500000000000008\",\n",
    "    \"LASST510000000000003\", \n",
    "    \"LASST510000000000008\",\n",
    "    \"LASST520000000000003\",\n",
    "    \"LASST520000000000008\",\n",
    "    \"LASST530000000000003\", \n",
    "    \"LASST530000000000008\", \n",
    "    \"LASST540000000000003\", \n",
    "    \"LASST540000000000008\",     \n",
    "    \"LASST550000000000003\", \n",
    "    \"LASST550000000000008\", \n",
    "    \"LASST560000000000003\", \n",
    "    \"LASST560000000000008\",\n",
    "]\n",
    "\n",
    "# make requests, get responses\n",
    "responses1 = request_for_series(series_ids, \"1976\", \"1995\", apikey=apikey)\n",
    "\n",
    "# validate the responses\n",
    "[check_response(r) for r in responses1]\n",
    "\n",
    "# extract data and metadata from responses\n",
    "df1, metadata1 = unpack_all_responses(responses1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4193b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data for date range: 1996 - 2015\n",
    "responses2 = request_for_series(series_ids, \"1996\", \"2015\", apikey=apikey)\n",
    "df2, metadata2 = unpack_all_responses(responses2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d694f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull data for date range: 2016 - 2021\n",
    "responses3 = request_for_series(series_ids, \"2016\", \"2021\", apikey=apikey)\n",
    "df3, metadata3 = unpack_all_responses(responses3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa9bfa",
   "metadata": {},
   "source": [
    "This project will also incorporate data related to the dates when states announced that Pandemic Unemployment Assistance benefits (PUA)\n",
    "\n",
    "will expire (announce_ui) in additon to the actual date when PUA ended (expired_ui). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "announce_url = \"https://raw.githubusercontent.com/vgm236/ferrante_moreira_data_project/main/Data/announced_dates_ui_expiration.csv\"\n",
    "announce_ui = pd.read_csv(announce_url)\n",
    "\n",
    "expired_url = \"https://raw.githubusercontent.com/vgm236/ferrante_moreira_data_project/main/Data/effective_dates_ui_expiration.csv\"\n",
    "expired_ui = pd.read_csv(expired_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7b2cf",
   "metadata": {},
   "source": [
    "Since the data was pulled in three batches, we will now combine to one large dataframe for unemployment and labor force participation values \n",
    "\n",
    "and one larger dataframe for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cd7812bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1976', '1977', '1978', '1979', '1980', '1981', '1982', '1983',\n",
       "       '1984', '1985', '1986', '1987', '1988', '1989', '1990', '1991',\n",
       "       '1992', '1993', '1994', '1995', '1996', '1997', '1998', '1999',\n",
       "       '2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007',\n",
       "       '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015',\n",
       "       '2016', '2017', '2018', '2019', '2020', '2021'], dtype=object)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create single dataframe for df1, df2, and df3\n",
    "df = pd.concat([df1, df2, df3])\n",
    "\n",
    "df = df.sort_values(by=[\"year\"]) \n",
    "\n",
    "df[\"year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f20c071b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single dataframe for metadata1, metadata2, metadata3\n",
    "metadata = pd.concat([metadata1, metadata2, metadata3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f9909",
   "metadata": {},
   "source": [
    "Since the Metadata dataframe is composed of both unemployment rate and labor force participation, we will separate accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c325a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe including only measure data types for unemployment rate\n",
    "df_ur = metadata.query(\"measure_data_type == 'unemployment rate'\")\n",
    "\n",
    "# Dataframe including only measure data types for labor force participation\n",
    "df_lfp = metadata.query(\"measure_data_type == 'labor force participation rate'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac40ae8",
   "metadata": {},
   "source": [
    "Now that we have the dataframes seperated by unemployment rate and labor force participation, we can map values from the df \n",
    "\n",
    "dataframe to the df_ur and df_lfp dataframes using series_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "34b1b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df on df_ur by series id to get each states unemployment rate\n",
    "df_ur_values = df_ur.merge(df, on=\"series_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "35714cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df on df_lfp by series id to get each states labor force participation rate\n",
    "df_lfp_values = df_lfp.merge(df, on=\"series_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "64918724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge unemployment announcement date and expiration date to single dataframe \n",
    "ui_dates = announce_ui.merge(expired_ui, on=\"state_abrev\", how=\"left\")\n",
    "\n",
    "# change to datetime \n",
    "ui_dates[\"effe_date\"] = pd.to_datetime(ui_dates[\"effe_date\"])\n",
    "ui_dates[\"annc_date\"] = pd.to_datetime(ui_dates[\"annc_date\"])\n",
    "\n",
    "# change state_abrev to area for future merging simplicity\n",
    "state = {\"state_abrev\" : \"area\"}\n",
    "ui_dates = ui_dates.rename(columns=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "552a74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change \"area\" values to abbrevations to allow for merging ui_dates  \n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York\": \"NY\",\n",
    "    \"North Carolina\": \"NC\",\n",
    "    \"North Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon\": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"South Carolina\": \"SC\",\n",
    "    \"South Dakota\": \"SD\",\n",
    "    \"Tennessee\": \"TN\",\n",
    "    \"Texas\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\"\n",
    "}\n",
    "\n",
    "df_ur_values[\"area\"] = df_ur_values[\"area\"].replace(us_state_to_abbrev)\n",
    "\n",
    "df_lfp_values[\"area\"] = df_lfp_values[\"area\"].replace(us_state_to_abbrev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "33810989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Temp/ipykernel_18540/2261253580.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ur_small[\"month\"] = df_ur_small[\"period\"].str.strip(\"M\").astype(int)\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp/ipykernel_18540/2261253580.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ur_small[\"date\"] = pd.to_datetime(df_ur_small[[\"year\", \"month\"]].assign(DAY=1))\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp/ipykernel_18540/2261253580.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lfp_small[\"month\"] = df_lfp_small[\"period\"].str.strip(\"M\").astype(int)\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp/ipykernel_18540/2261253580.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lfp_small[\"date\"] = pd.to_datetime(df_lfp_small[[\"year\", \"month\"]].assign(DAY=1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">unemployment_rate</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">labor_force_participation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <th>Alabama</th>\n",
       "      <th>Alaska</th>\n",
       "      <th>Arizona</th>\n",
       "      <th>Arkansas</th>\n",
       "      <th>California</th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Connecticut</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>District of Columbia</th>\n",
       "      <th>Florida</th>\n",
       "      <th>...</th>\n",
       "      <th>South Dakota</th>\n",
       "      <th>Tennessee</th>\n",
       "      <th>Texas</th>\n",
       "      <th>Utah</th>\n",
       "      <th>Vermont</th>\n",
       "      <th>Virginia</th>\n",
       "      <th>Washington</th>\n",
       "      <th>West Virginia</th>\n",
       "      <th>Wisconsin</th>\n",
       "      <th>Wyoming</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1976-01-01</th>\n",
       "      <td>6.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>...</td>\n",
       "      <td>64.6</td>\n",
       "      <td>59.6</td>\n",
       "      <td>63.8</td>\n",
       "      <td>62.8</td>\n",
       "      <td>63.6</td>\n",
       "      <td>65.9</td>\n",
       "      <td>60.9</td>\n",
       "      <td>52.5</td>\n",
       "      <td>65.6</td>\n",
       "      <td>65.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976-02-01</th>\n",
       "      <td>6.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>...</td>\n",
       "      <td>64.4</td>\n",
       "      <td>59.4</td>\n",
       "      <td>63.5</td>\n",
       "      <td>62.6</td>\n",
       "      <td>63.4</td>\n",
       "      <td>65.8</td>\n",
       "      <td>60.7</td>\n",
       "      <td>52.4</td>\n",
       "      <td>65.5</td>\n",
       "      <td>64.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976-03-01</th>\n",
       "      <td>6.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>9.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>...</td>\n",
       "      <td>64.4</td>\n",
       "      <td>59.3</td>\n",
       "      <td>63.4</td>\n",
       "      <td>62.5</td>\n",
       "      <td>63.2</td>\n",
       "      <td>65.6</td>\n",
       "      <td>60.6</td>\n",
       "      <td>52.3</td>\n",
       "      <td>65.4</td>\n",
       "      <td>64.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976-04-01</th>\n",
       "      <td>6.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>64.3</td>\n",
       "      <td>59.3</td>\n",
       "      <td>63.5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>63.5</td>\n",
       "      <td>65.5</td>\n",
       "      <td>60.6</td>\n",
       "      <td>52.3</td>\n",
       "      <td>65.4</td>\n",
       "      <td>64.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976-05-01</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>9.3</td>\n",
       "      <td>...</td>\n",
       "      <td>64.3</td>\n",
       "      <td>59.4</td>\n",
       "      <td>63.6</td>\n",
       "      <td>62.6</td>\n",
       "      <td>63.6</td>\n",
       "      <td>65.4</td>\n",
       "      <td>60.7</td>\n",
       "      <td>52.2</td>\n",
       "      <td>65.5</td>\n",
       "      <td>65.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01</th>\n",
       "      <td>3.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.7</td>\n",
       "      <td>60.7</td>\n",
       "      <td>62.2</td>\n",
       "      <td>67.4</td>\n",
       "      <td>60.6</td>\n",
       "      <td>62.7</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.2</td>\n",
       "      <td>66.3</td>\n",
       "      <td>64.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-01</th>\n",
       "      <td>3.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>...</td>\n",
       "      <td>68.7</td>\n",
       "      <td>60.6</td>\n",
       "      <td>62.3</td>\n",
       "      <td>67.8</td>\n",
       "      <td>60.9</td>\n",
       "      <td>62.8</td>\n",
       "      <td>63.3</td>\n",
       "      <td>55.2</td>\n",
       "      <td>66.4</td>\n",
       "      <td>64.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-01</th>\n",
       "      <td>3.1</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.7</td>\n",
       "      <td>60.6</td>\n",
       "      <td>62.3</td>\n",
       "      <td>67.9</td>\n",
       "      <td>61.2</td>\n",
       "      <td>62.9</td>\n",
       "      <td>63.5</td>\n",
       "      <td>55.2</td>\n",
       "      <td>66.5</td>\n",
       "      <td>64.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-01</th>\n",
       "      <td>3.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>68.7</td>\n",
       "      <td>60.3</td>\n",
       "      <td>62.4</td>\n",
       "      <td>67.9</td>\n",
       "      <td>61.3</td>\n",
       "      <td>62.9</td>\n",
       "      <td>63.5</td>\n",
       "      <td>55.2</td>\n",
       "      <td>66.5</td>\n",
       "      <td>64.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-01</th>\n",
       "      <td>3.1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>68.7</td>\n",
       "      <td>60.1</td>\n",
       "      <td>62.5</td>\n",
       "      <td>67.9</td>\n",
       "      <td>61.3</td>\n",
       "      <td>63.0</td>\n",
       "      <td>63.6</td>\n",
       "      <td>55.2</td>\n",
       "      <td>66.4</td>\n",
       "      <td>63.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           unemployment_rate                                              \\\n",
       "area                 Alabama Alaska Arizona Arkansas California Colorado   \n",
       "date                                                                       \n",
       "1976-01-01               6.6    7.1    10.2      7.3        9.2      5.8   \n",
       "1976-02-01               6.6    7.1    10.2      7.3        9.2      5.7   \n",
       "1976-03-01               6.6    7.0    10.1      7.3        9.1      5.7   \n",
       "1976-04-01               6.5    6.9    10.0      7.2        9.1      5.6   \n",
       "1976-05-01               6.4    6.9     9.8      7.1        9.0      5.6   \n",
       "...                      ...    ...     ...      ...        ...      ...   \n",
       "2021-06-01               3.3    6.6     6.8      4.4        7.6      6.2   \n",
       "2021-07-01               3.2    6.6     6.6      4.3        7.6      6.1   \n",
       "2021-08-01               3.1    6.4     6.2      4.2        7.5      5.9   \n",
       "2021-09-01               3.1    6.3     5.7      4.0        7.5      5.6   \n",
       "2021-10-01               3.1    6.1     5.2      3.7        7.3      5.4   \n",
       "\n",
       "                                                              ...  \\\n",
       "area       Connecticut Delaware District of Columbia Florida  ...   \n",
       "date                                                          ...   \n",
       "1976-01-01         9.8      8.0                  8.7     9.7  ...   \n",
       "1976-02-01         9.8      8.0                  8.7     9.7  ...   \n",
       "1976-03-01         9.8      8.0                  8.6     9.6  ...   \n",
       "1976-04-01         9.6      8.1                  8.5     9.5  ...   \n",
       "1976-05-01         9.4      8.3                  8.4     9.3  ...   \n",
       "...                ...      ...                  ...     ...  ...   \n",
       "2021-06-01         7.7      5.8                  7.0     5.0  ...   \n",
       "2021-07-01         7.3      5.6                  6.7     5.1  ...   \n",
       "2021-08-01         7.2      5.4                  6.7     5.0  ...   \n",
       "2021-09-01         6.8      5.4                  6.6     4.8  ...   \n",
       "2021-10-01         6.4      5.3                  6.3     4.6  ...   \n",
       "\n",
       "           labor_force_participation                                         \\\n",
       "area                    South Dakota Tennessee Texas  Utah Vermont Virginia   \n",
       "date                                                                          \n",
       "1976-01-01                      64.6      59.6  63.8  62.8    63.6     65.9   \n",
       "1976-02-01                      64.4      59.4  63.5  62.6    63.4     65.8   \n",
       "1976-03-01                      64.4      59.3  63.4  62.5    63.2     65.6   \n",
       "1976-04-01                      64.3      59.3  63.5  62.5    63.5     65.5   \n",
       "1976-05-01                      64.3      59.4  63.6  62.6    63.6     65.4   \n",
       "...                              ...       ...   ...   ...     ...      ...   \n",
       "2021-06-01                      68.7      60.7  62.2  67.4    60.6     62.7   \n",
       "2021-07-01                      68.7      60.6  62.3  67.8    60.9     62.8   \n",
       "2021-08-01                      68.7      60.6  62.3  67.9    61.2     62.9   \n",
       "2021-09-01                      68.7      60.3  62.4  67.9    61.3     62.9   \n",
       "2021-10-01                      68.7      60.1  62.5  67.9    61.3     63.0   \n",
       "\n",
       "                                                       \n",
       "area       Washington West Virginia Wisconsin Wyoming  \n",
       "date                                                   \n",
       "1976-01-01       60.9          52.5      65.6    65.3  \n",
       "1976-02-01       60.7          52.4      65.5    64.9  \n",
       "1976-03-01       60.6          52.3      65.4    64.7  \n",
       "1976-04-01       60.6          52.3      65.4    64.9  \n",
       "1976-05-01       60.7          52.2      65.5    65.2  \n",
       "...               ...           ...       ...     ...  \n",
       "2021-06-01       63.1          55.2      66.3    64.8  \n",
       "2021-07-01       63.3          55.2      66.4    64.6  \n",
       "2021-08-01       63.5          55.2      66.5    64.3  \n",
       "2021-09-01       63.5          55.2      66.5    64.1  \n",
       "2021-10-01       63.6          55.2      66.4    63.9  \n",
       "\n",
       "[550 rows x 100 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Preparation for analyses\n",
    "\n",
    "# Create smaller DataFrames for UR and LFP with only necessary columns\n",
    "df_ur_small = df_ur_values[[\"area\", \"year\", \"period\", \"value\"]]\n",
    "df_lfp_small = df_lfp_values[[\"area\", \"year\", \"period\", \"value\"]]\n",
    "\n",
    "# Remove the M from period to create an integer for the month, then create a new column which is the date (Year-Month-Day)\n",
    "df_ur_small[\"month\"] = df_ur_small[\"period\"].str.strip(\"M\").astype(int) \n",
    "df_ur_small[\"date\"] = pd.to_datetime(df_ur_small[[\"year\", \"month\"]].assign(DAY=1))\n",
    "\n",
    "df_lfp_small[\"month\"] = df_lfp_small[\"period\"].str.strip(\"M\").astype(int)\n",
    "df_lfp_small[\"date\"] = pd.to_datetime(df_lfp_small[[\"year\", \"month\"]].assign(DAY=1))\n",
    "\n",
    "# Re-label values in both DataFrames so it is clear which refers to UR and LFP once merged\n",
    "ur_value_name = {\"value\" : \"unemployment_rate\"}\n",
    "lfp_value_name = {\"value\" : \"labor_force_participation\"}\n",
    "\n",
    "df_ur_small = df_ur_small.rename(columns=ur_value_name)\n",
    "df_lfp_small = df_lfp_small.rename(columns=lfp_value_name)\n",
    "\n",
    "# Drop uncessary columns\n",
    "df_ur_small = df_ur_small[[\"area\", \"unemployment_rate\", \"date\"]]\n",
    "df_lfp_small = df_lfp_small[[\"area\", \"labor_force_participation\", \"date\"]]\n",
    "\n",
    "# Merge the two Dataframe on area and year\n",
    "df_ur_lfp = df_ur_small.merge(\n",
    "    df_lfp_small, how='left', \n",
    "    left_on=['area', 'date'], \n",
    "    right_on=['area', 'date']\n",
    "    ).drop_duplicates(subset=[\"area\", \"date\"])\n",
    "\n",
    "# Turn UR and LFP values to float \n",
    "df_ur_lfp[\"unemployment_rate\"] = df_ur_lfp[\"unemployment_rate\"].astype(float)\n",
    "df_ur_lfp[\"labor_force_participation\"] = df_ur_lfp[\"labor_force_participation\"].astype(float)\n",
    "\n",
    "# Reshape data for analyses\n",
    "df_ur_lfp = df_ur_lfp.pivot(\n",
    "    index=\"date\", \n",
    "    columns=\"area\", \n",
    "    values=[\"unemployment_rate\", \"labor_force_participation\"])\n",
    "\n",
    "df_ur_lfp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
